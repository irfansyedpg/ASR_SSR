{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/syed.irfanullah/Desktop/speech/gcpcri.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_metadata(speech_file):\n",
    "    \"\"\"Send a request that includes recognition metadata.\"\"\"\n",
    "    # [START speech_transcribe_recognition_metadata_beta]\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    # Here we construct a recognition metadata object.\n",
    "    # Most metadata fields are specified as enums that can be found\n",
    "    # in speech.enums.RecognitionMetadata\n",
    "    metadata = speech.types.RecognitionMetadata()\n",
    "    metadata.interaction_type = (\n",
    "        speech.enums.RecognitionMetadata.InteractionType.DISCUSSION)\n",
    "    metadata.microphone_distance = (\n",
    "        speech.enums.RecognitionMetadata.MicrophoneDistance.NEARFIELD)\n",
    "    metadata.recording_device_type = (\n",
    "        speech.enums.RecognitionMetadata.RecordingDeviceType.SMARTPHONE)\n",
    "    # Some metadata fields are free form strings\n",
    "    metadata.recording_device_name = \"Pixel 2 XL\"\n",
    "    # And some are integers, for instance the 6 digit NAICS code\n",
    "    # https://www.naics.com/search/\n",
    "    metadata.industry_naics_code_of_audio = 519190\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='ur-PK',\n",
    "        # Add this in the request to send metadata.\n",
    "        metadata=metadata)\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        print('-' * 20)\n",
    "        print('First alternative of result {}'.format(i))\n",
    "        print('Transcript: {}'.format(alternative.transcript))\n",
    "    # [END speech_transcribe_recognition_metadata_beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_diarization(speech_file,languagecode):\n",
    "    \"\"\"Transcribe the given audio file synchronously with diarization.\"\"\"\n",
    "    # [START speech_transcribe_diarization_beta]\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "   \n",
    "\n",
    "    with open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=44100,\n",
    "         audio_channel_count=2,\n",
    "        language_code=languagecode,\n",
    "        enable_speaker_diarization=True,\n",
    "        enable_automatic_punctuation=True,\n",
    "        diarization_speaker_count=2)\n",
    "\n",
    "    print('Waiting for operation to complete...')\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result:\n",
    "    result = response.results[-1]\n",
    "\n",
    "    words_info = result.alternatives[0].words\n",
    "    confidence = result.alternatives[0].confidence\n",
    "    print(\"confidence '{}'\". result.alternatives[0].confidence)\n",
    "    print(\"transcript '{}'\". result.alternatives[0].transcript)\n",
    "    \n",
    "\n",
    "\n",
    "    # Printing out the output:\n",
    "    for word_info in words_info:\n",
    "           print(\"word: '{}', speaker_tag: {}\".format(word_info.word,\n",
    "                                                   word_info.speaker_tag))\n",
    "    # [END speech_transcribe_diarization_beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-012d4e45ac51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranscribe_file_with_diarization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"one.wav\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"en-US\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-57bceee0aabf>\u001b[0m in \u001b[0;36mtranscribe_file_with_diarization\u001b[1;34m(speech_file, languagecode)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mwords_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"confidence '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"transcript '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malternatives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "transcribe_file_with_diarization(\"one.wav\",\"en-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
